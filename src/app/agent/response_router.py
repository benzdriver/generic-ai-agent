# src/app/agent/response_router.py

"""
æ¨¡å—åç§°ï¼šresponse_router.py

åŠŸèƒ½ï¼š
- å¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶ç”Ÿæˆå›ç­”
- åˆ©ç”¨å¤šä¸ªçŸ¥è¯†åº“é›†åˆæä¾›æ›´å‡†ç¡®çš„å›ç­”
- æ”¯æŒå¯¹è¯å†å²å’ŒæŸ¥è¯¢å¤ç”¨
"""

from typing import Dict, Any, List, Optional
from qdrant_client import models
from qdrant_client.http.models import ScoredPoint, Record
from src.infrastructure.vector_store.base import BaseVectorStore
from src.infrastructure.vector_store.qdrant import QdrantVectorStore
from src.infrastructure.vector_store.embedding_router import get_embedding
from src.app.agent.prompt_builder import build_prompt
from src.infrastructure.llm.base import BaseLLM
from src.app.ingestion.qa_logger import log_qa_to_knowledge_base
from src.app.agent.query_normalizer import transform_query_to_canonical_form
from src.infrastructure.config.domain_manager import get_domain_manager
from src.infrastructure.config.env_manager import get_config

# è·å–ç³»ç»Ÿé…ç½®
config = get_config()
domain_manager = get_domain_manager()

def get_conversation_context(user_id: str, vector_store: BaseVectorStore, limit: int = 5) -> List[Record]:
    """è·å–ç”¨æˆ·æœ€è¿‘çš„å¯¹è¯å†å²"""
    results = vector_store.scroll(
        collection_name=QdrantVectorStore.CONVERSATION_COLLECTION,
        scroll_filter=models.Filter(
            must=[
                models.FieldCondition(
                    key="user_id",
                    match=models.MatchValue(value=user_id)
                )
            ]
        ),
        limit=limit,
        with_payload=True,
        with_vectors=False
    )
    return results[0] if results else []

def find_similar_canonical_query(query: str, vector_store: BaseVectorStore, threshold: float = 0.8) -> Optional[ScoredPoint]:
    """æŸ¥æ‰¾ç›¸ä¼¼çš„æ ‡å‡†åŒ–æŸ¥è¯¢"""
    results = vector_store.search(
        collection_name=QdrantVectorStore.CANONICAL_COLLECTION,
        query_vector=get_embedding(query),
        limit=1,
        score_threshold=threshold
    )
    return results[0] if results else None

def retrieve_relevant_documents(query: str, vector_store: BaseVectorStore, domain: Optional[str] = None, top_k: int = 3) -> List[ScoredPoint]:
    """ä»æ–‡æ¡£åº“ä¸­æ£€ç´¢ç›¸å…³å†…å®¹
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        domain: é¢†åŸŸåç§°ï¼Œç”¨äºç¡®å®šä½¿ç”¨å“ªä¸ªå‘é‡é›†åˆ
        top_k: è¿”å›çš„æœ€å¤§ç»“æœæ•°
        
    Returns:
        list: æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
    """
    collection_name = QdrantVectorStore.DOCUMENT_COLLECTION
    if domain:
        domain_collection = domain_manager.get_domain_collection(domain)
        if domain_collection:
            collection_name = domain_collection
    
    results = vector_store.search(
        collection_name=collection_name,
        query_vector=get_embedding(query),
        limit=top_k
    )
    return results

def is_complex_query(query: str, llm: BaseLLM) -> bool:
    """åˆ¤æ–­æŸ¥è¯¢æ˜¯å¦å¤æ‚ï¼Œéœ€è¦è¯¦ç»†å›ç­”"""
    # ç®€å•å¯å‘å¼è§„åˆ™
    if len(query) > 50:  # é•¿é—®é¢˜é€šå¸¸æ›´å¤æ‚
        return True
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤æ‚å…³é”®è¯
    complex_keywords = [
        "æ­¥éª¤", "æµç¨‹", "æ€ä¹ˆåŠ", "ç”³è¯·æ¡ä»¶", "æ‰€éœ€ææ–™", "æ—¶é—´çº¿", 
        "requirements", "process", "steps", "timeline", "documents needed",
        "è¯¦ç»†", "å…·ä½“", "complete", "detailed"
    ]
    
    query_lower = query.lower()
    if any(keyword in query_lower for keyword in complex_keywords):
        return True
    
    return False

def get_user_context_summary(user_id: str, vector_store: BaseVectorStore) -> str:
    """è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡æ‘˜è¦"""
    context_records = get_conversation_context(user_id, vector_store, limit=3)
    
    if not context_records:
        return "æ–°ç”¨æˆ·ï¼Œæ— å†å²å¯¹è¯è®°å½•"
    
    # æ„å»ºç®€å•çš„ä¸Šä¸‹æ–‡æ‘˜è¦
    recent_topics = []
    for record in context_records:
        if 'question' in record.payload:
            question = record.payload['question'][:100]  # æˆªå–å‰100å­—ç¬¦
            recent_topics.append(f"- {question}")
    
    if recent_topics:
        return f"ç”¨æˆ·æœ€è¿‘è¯¢é—®è¿‡ï¼š\n" + "\n".join(recent_topics[-2:])  # åªæ˜¾ç¤ºæœ€è¿‘2ä¸ª
    else:
        return "ç”¨æˆ·æœ‰å†å²å¯¹è¯ï¼Œä½†æ— æ³•è§£æ"

def is_immigration_related(query: str) -> bool:
    """æ£€æµ‹æŸ¥è¯¢æ˜¯å¦ä¸ç§»æ°‘ç›¸å…³ï¼ˆä½¿ç”¨è½»é‡çº§å…³é”®è¯åŒ¹é…ï¼Œä¸è°ƒç”¨LLM APIï¼‰"""
    query_lower = query.lower()
    
    # æ˜ç¡®çš„ç§»æ°‘å…³é”®è¯
    immigration_keywords = [
        "ç§»æ°‘", "ç­¾è¯", "express entry", "pnp", "å·¥ç­¾", "å­¦ç­¾", "æ°¸ä¹…å±…æ°‘", "pr", "citizenship",
        "immigration", "visa", "permit", "resident", "sponsor", "family class", "refugee",
        "cec", "fsw", "skilled worker", "provincial nominee", "lmia", "ielts", "celpip",
        "æ«å¶å¡", "å…¥ç±", "å›¢èš", "é›…æ€", "è¯­è¨€è€ƒè¯•", "åŠ æ‹¿å¤§ç§»æ°‘", "ç”³è¯·ç§»æ°‘", "ç§»æ°‘æ¡ä»¶",
        "ç§»æ°‘æ”¿ç­–", "ç§»æ°‘æ³•", "ç§»æ°‘é¡¾é—®", "ç”³è¯·pr", "ç§»æ°‘é¡¹ç›®", "ç§»æ°‘æ—¶é—´", "ç§»æ°‘è´¹ç”¨",
        "canada", "canadian", "åŠ æ‹¿å¤§", "ç”³è¯·", "æ¡ä»¶", "è¦æ±‚", "æµç¨‹", "ææ–™", "è´¹ç”¨"
    ]
    
    # éç§»æ°‘å…³é”®è¯ï¼ˆæ˜ç¡®æ’é™¤ï¼‰
    non_immigration_keywords = [
        "æ±½è½¦", "suv", "car", "vehicle", "automobile", "æˆ¿åœ°äº§", "ä¹°æˆ¿", "æˆ¿ä»·", "æŠ•èµ„", "è‚¡ç¥¨", "åŸºé‡‘",
        "åŒ»ç–—", "çœ‹ç—…", "åŒ»é™¢", "ä¿é™©", "å¤©æ°”", "æ—…æ¸¸", "ç¾é£Ÿ", "è´­ç‰©", "ç”µå½±", "ç”µè§†", "éŸ³ä¹", 
        "ä½“è‚²", "æ¸¸æˆ", "æŠ€æœ¯", "ç¼–ç¨‹", "è½¯ä»¶", "ç¡¬ä»¶", "å¨±ä¹", "æ–°é—»", "æ”¿æ²»", "ç»æµ",
        "æ•°å­¦", "ç‰©ç†", "åŒ–å­¦", "å†å²", "åœ°ç†", "æ–‡å­¦", "è‰ºæœ¯", "ç§‘å­¦", "æ•™è‚²", "å­¦æ ¡",
        "å·¥ä½œ", "æ±‚èŒ", "ç®€å†", "é¢è¯•", "è–ªæ°´", "åˆ›ä¸š", "ç”Ÿæ„", "é¤å…", "é…’åº—", "é£æœº",
        "ç«è½¦", "å…¬äº¤", "åœ°é“", "æ‰‹æœº", "ç”µè„‘", "ç½‘ç«™", "app", "ç¤¾äº¤", "çº¦ä¼š", "ç»“å©š",
        "å® ç‰©", "åŠ¨ç‰©", "æ¤ç‰©", "èŠ±å›­", "è£…ä¿®", "å®¶å…·", "æœè£…", "åŒ–å¦†", "å¥èº«", "è¿åŠ¨"
    ]
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç§»æ°‘å…³é”®è¯
    has_immigration_keywords = any(keyword in query_lower for keyword in immigration_keywords)
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«éç§»æ°‘å…³é”®è¯
    has_non_immigration_keywords = any(keyword in query_lower for keyword in non_immigration_keywords)
    
    # å¦‚æœæ˜ç¡®åŒ…å«éç§»æ°‘å…³é”®è¯ä¸”ä¸åŒ…å«ç§»æ°‘å…³é”®è¯ï¼Œåˆ¤å®šä¸ºéç§»æ°‘ç›¸å…³
    if has_non_immigration_keywords and not has_immigration_keywords:
        return False
    
    # å¦‚æœåŒ…å«ç§»æ°‘å…³é”®è¯ï¼Œåˆ¤å®šä¸ºç§»æ°‘ç›¸å…³
    if has_immigration_keywords:
        return True
    
    # å¯¹äºæ¨¡ç³Šçš„æƒ…å†µï¼Œä½¿ç”¨ç®€å•çš„é•¿åº¦åˆ¤æ–­
    # å¦‚æœæ˜¯å¾ˆçŸ­çš„é—®å€™è¯­æˆ–ç®€å•é—®é¢˜ï¼Œåˆ¤å®šä¸ºå¯èƒ½ç›¸å…³ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
    if len(query.strip()) < 15:
        return True
    
    # é»˜è®¤æƒ…å†µä¸‹ï¼Œå‡è®¾ä¸ç§»æ°‘ç›¸å…³ï¼ˆä¿å®ˆç­–ç•¥ï¼Œé¿å…è¯¯åˆ¤ï¼‰
    return True

def generate_non_immigration_response() -> str:
    """ç”Ÿæˆéç§»æ°‘é—®é¢˜çš„æ ‡å‡†å›å¤"""
    return """
æŠ±æ­‰ï¼Œæˆ‘æ˜¯Thinkforward AIç§»æ°‘å’¨è¯¢çš„ä¸“ä¸šAIåŠ©æ‰‹å°æ€ï¼Œåªèƒ½å›ç­”ä¸åŠ æ‹¿å¤§ç§»æ°‘ç›¸å…³çš„é—®é¢˜ã€‚

ğŸ¯ æˆ‘å¯ä»¥å¸®æ‚¨è§£ç­”ï¼š
â€¢ å„ç±»åŠ æ‹¿å¤§ç§»æ°‘é¡¹ç›®ï¼ˆExpress Entryã€PNPç­‰ï¼‰
â€¢ ç­¾è¯ç”³è¯·æµç¨‹å’Œè¦æ±‚
â€¢ ç§»æ°‘æ”¿ç­–è§£è¯»å’Œåˆ†æ
â€¢ ç”³è¯·æ¡ä»¶è¯„ä¼°å’Œææ–™å‡†å¤‡
â€¢ ç§»æ°‘æ—¶é—´çº¿å’Œè´¹ç”¨å’¨è¯¢

ğŸ’¡ ä¸å¦¨é—®æˆ‘è¿™äº›é—®é¢˜ï¼š
"Express Entryéœ€è¦ä»€ä¹ˆæ¡ä»¶ï¼Ÿ"
"æˆ‘å¯ä»¥ç”³è¯·å“ªä¸ªçœæåé¡¹ç›®ï¼Ÿ"
"é…å¶æ‹…ä¿ç§»æ°‘éœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ"

ğŸ“ å¦‚éœ€å…¶ä»–æœåŠ¡æˆ–äººå·¥å’¨è¯¢ï¼š
ğŸ“§ ä¸“ä¸šå’¨è¯¢: contact@thinkforward.ai
ğŸŒ å®˜æ–¹ç½‘ç«™: www.thinkforward.ai
"""

def generate_response(
    user_query: str, 
    llm: BaseLLM,
    vector_store: BaseVectorStore,
    user_id: Optional[str] = None, 
    domain: Optional[str] = None
) -> str:
    """ç”Ÿæˆå›ç­”
    
    Args:
        user_query: ç”¨æˆ·æŸ¥è¯¢
        user_id: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼‰
        domain: é¢†åŸŸåç§°ï¼ˆå¯é€‰ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨ç³»ç»Ÿé…ç½®çš„é»˜è®¤é¢†åŸŸ
        
    Returns:
        str: ç”Ÿæˆçš„å›ç­”
    """
    if domain is None:
        domain = config.domains.default_domain
    
    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºç§»æ°‘ç›¸å…³é—®é¢˜ï¼ˆä»…å¯¹ç§»æ°‘é¢†åŸŸè¿›è¡Œè¾¹ç•Œæ£€æµ‹ï¼‰
    # ä½¿ç”¨è½»é‡çº§å…³é”®è¯æ£€æµ‹ï¼Œä¸è°ƒç”¨LLM APIï¼ŒèŠ‚çœæˆæœ¬
    if domain in ["immigration_consultant", "immigration"]:
        if not is_immigration_related(user_query):
            return generate_non_immigration_response()
    
    # è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡
    user_context_summary = ""
    if user_id:
        user_context_summary = get_user_context_summary(user_id, vector_store)
    
    canonical_query = transform_query_to_canonical_form(user_query, llm=llm, vector_store=vector_store)
    
    similar_query = find_similar_canonical_query(canonical_query, vector_store)
    if similar_query and similar_query.score > 0.9:
        return similar_query.payload["answer"]
    
    relevant_docs = retrieve_relevant_documents(canonical_query, vector_store, domain=domain)
    doc_contents = [doc.payload["content"] for doc in relevant_docs]
    
    # æ™ºèƒ½é€‰æ‹©æ¨¡æ¿ï¼šæ ¹æ®é—®é¢˜å¤æ‚åº¦
    template_domain = domain
    if domain == "immigration_consultant" or domain == "immigration":
        if is_complex_query(user_query, llm):
            template_domain = "immigration_detailed"
        else:
            template_domain = "immigration"
    
    prompt = build_prompt(user_query, doc_contents, domain=template_domain)
    
    # å¦‚æœæœ‰ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼Œæ·»åŠ åˆ°promptä¸­
    if user_context_summary and user_context_summary != "æ–°ç”¨æˆ·ï¼Œæ— å†å²å¯¹è¯è®°å½•":
        prompt = f"ã€ç”¨æˆ·èƒŒæ™¯ã€‘\n{user_context_summary}\n\n{prompt}"
    
    domain_llm_config = domain_manager.get_domain_llm_config(domain)
    
    if domain_llm_config:
        provider = domain_llm_config.get('preferred_provider')
        model_params = domain_llm_config.get('model_params', {})
        # ä¸ºäº†è·å¾—æ›´ç®€æ´çš„å›ç­”ï¼Œè°ƒæ•´å‚æ•°
        model_params['temperature'] = model_params.get('temperature', 0.2)  # é™ä½åˆ›é€ æ€§
        model_params['top_p'] = model_params.get('top_p', 0.8)  # æé«˜ä¸€è‡´æ€§
        response = llm.generate(prompt, provider=provider, **model_params)
    else:
        response = llm.generate(prompt, temperature=0.2, top_p=0.8)
    
    log_qa_to_knowledge_base(user_query, response, vector_store, user_id=user_id, llm=llm)
    
    return response
