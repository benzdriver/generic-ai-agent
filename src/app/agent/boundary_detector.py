"""
æ™ºèƒ½è¾¹ç•Œæ£€æµ‹å™¨
ä½¿ç”¨çŸ¥è¯†åº“åŠ¨æ€åˆ¤æ–­æŸ¥è¯¢æ˜¯å¦ä¸ç§»æ°‘ç›¸å…³ï¼Œé¿å…ç¡¬ç¼–ç å…³é”®è¯ç»´æŠ¤é—®é¢˜
"""

from typing import List, Tuple
import logging
from src.infrastructure.vector_store.base import BaseVectorStore
from src.infrastructure.vector_store.embedding_router import get_embedding

logger = logging.getLogger(__name__)

class IntelligentBoundaryDetector:
    """æ™ºèƒ½è¾¹ç•Œæ£€æµ‹å™¨ - åŸºäºçŸ¥è¯†åº“çš„åŠ¨æ€åˆ¤æ–­"""
    
    def __init__(self, vector_store: BaseVectorStore):
        self.vector_store = vector_store
        
        # åŸºç¡€é…ç½®
        self.immigration_threshold = 0.4  # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆåŸºäºæµ‹è¯•åˆ†æè°ƒæ•´ï¼‰
        self.max_search_results = 5
        
        # æ˜ç¡®çš„æ’é™¤è¯ï¼ˆéå¸¸ç¡®å®šä¸ç§»æ°‘æ— å…³ï¼‰
        self.explicit_exclude_keywords = [
            "å¤©æ°”", "weather", "ä»Šå¤©å‡ å·", "ç°åœ¨å‡ ç‚¹", "ä½ å¥½", "hello", "è°¢è°¢", "thank you",
            "å†è§", "goodbye", "èŠå¤©", "chat", "è®²ä¸ªç¬‘è¯", "tell me a joke",
            "å”±æ­Œ", "sing", "è·³èˆ", "dance", "æ¸¸æˆ", "game", "ç”µå½±æ¨è", "movie recommendation",
            "æ±½è½¦æ¨è", "ä¹°è½¦", "è½¦å‹æ¨è", "æ±½è½¦å“ç‰Œ", "äºŒæ‰‹è½¦", "æ–°è½¦", "è½¦è¾†", "æ±½è½¦ä»·æ ¼"
        ]
        
    def is_immigration_related(self, query: str, domain: str = "immigration_consultant") -> Tuple[bool, float, str]:
        """
        ä½¿ç”¨çŸ¥è¯†åº“åˆ¤æ–­æŸ¥è¯¢æ˜¯å¦ä¸ç§»æ°‘ç›¸å…³
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            domain: é¢†åŸŸåç§°
            
        Returns:
            Tuple[bool, float, str]: (æ˜¯å¦ç›¸å…³, ç½®ä¿¡åº¦åˆ†æ•°, åˆ¤æ–­ç†ç”±)
        """
        query_lower = query.lower().strip()
        
        # ç¬¬ä¸€å±‚ï¼šæ˜ç¡®æ’é™¤çš„é€šç”¨è¯æ±‡
        if any(exclude in query_lower for exclude in self.explicit_exclude_keywords):
            return False, 0.0, "æ˜ç¡®çš„éç§»æ°‘é€šç”¨æŸ¥è¯¢"
        
        # ç¬¬äºŒå±‚ï¼šä½¿ç”¨å‘é‡æœç´¢åœ¨çŸ¥è¯†åº“ä¸­æŸ¥æ‰¾ç›¸å…³å†…å®¹
        try:
            similarity_score, reason = self._search_knowledge_base(query, domain)
            
            # åˆ¤æ–­æ˜¯å¦ç›¸å…³
            is_related = similarity_score >= self.immigration_threshold
            
            logger.info(f"è¾¹ç•Œæ£€æµ‹ - æŸ¥è¯¢: '{query[:50]}...', ç›¸ä¼¼åº¦: {similarity_score:.3f}, ç›¸å…³: {is_related}")
            
            return is_related, similarity_score, reason
            
        except Exception as e:
            logger.error(f"çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥: {e}")
            # å‡ºé”™æ—¶é‡‡ç”¨ä¿å®ˆç­–ç•¥ï¼Œå‡è®¾ç›¸å…³
            return True, 0.5, "çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥ï¼Œä¿å®ˆåˆ¤æ–­ä¸ºç›¸å…³"
    
    def _search_knowledge_base(self, query: str, domain: str) -> Tuple[float, str]:
        """åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³å†…å®¹"""
        
        # è·å–æŸ¥è¯¢çš„å‘é‡è¡¨ç¤º
        query_vector = get_embedding(query)
        
        # åœ¨ä¸»è¦é›†åˆä¸­æœç´¢ï¼ˆä½¿ç”¨å®é™…å­˜åœ¨çš„é›†åˆåç§°ï¼‰
        collection_names = [
            "immigration_docs",        # ç§»æ°‘æ–‡æ¡£
            "merged_knowledge",        # åˆå¹¶çš„çŸ¥è¯†åº“
            "canonical_queries",       # æ ‡å‡†åŒ–æŸ¥è¯¢
            "conversations",           # å†å²å¯¹è¯
            "documents"                # é€šç”¨æ–‡æ¡£
        ]
        
        max_similarity = 0.0
        best_match_content = ""
        
        for collection_name in collection_names:
            try:
                # åœ¨å½“å‰é›†åˆä¸­æœç´¢
                results = self.vector_store.search(
                    collection_name=collection_name,
                    query_vector=query_vector,
                    limit=self.max_search_results
                )
                
                if results:
                    # è·å–æœ€é«˜ç›¸ä¼¼åº¦
                    top_score = results[0].score if results else 0.0
                    
                    if top_score > max_similarity:
                        max_similarity = top_score
                        best_match_content = results[0].payload.get("content", "")[:100]
                        
            except Exception as e:
                logger.warning(f"æœç´¢é›†åˆ {collection_name} å¤±è´¥: {e}")
                continue
        
        # ç”Ÿæˆåˆ¤æ–­ç†ç”±
        if max_similarity >= self.immigration_threshold:
            reason = f"åœ¨çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³å†…å®¹ (ç›¸ä¼¼åº¦: {max_similarity:.3f}): {best_match_content[:50]}..."
        else:
            reason = f"çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ (æœ€é«˜ç›¸ä¼¼åº¦: {max_similarity:.3f})"
            
        return max_similarity, reason
    
    def test_keyword_in_knowledge_base(self, keyword: str) -> dict:
        """æµ‹è¯•ç‰¹å®šå…³é”®è¯åœ¨çŸ¥è¯†åº“ä¸­çš„ç›¸å…³æ€§"""
        is_related, score, reason = self.is_immigration_related(keyword)
        
        return {
            "keyword": keyword,
            "is_immigration_related": is_related,
            "similarity_score": score,
            "reason": reason,
            "threshold": self.immigration_threshold
        }

# è¾…åŠ©å‡½æ•°ï¼šæµ‹è¯•å¤šä¸ªå…³é”®è¯
def test_multiple_keywords(detector: IntelligentBoundaryDetector, keywords: List[str]) -> List[dict]:
    """æ‰¹é‡æµ‹è¯•å…³é”®è¯"""
    results = []
    for keyword in keywords:
        result = detector.test_keyword_in_knowledge_base(keyword)
        results.append(result)
    return results

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
def demo_intelligent_detection(vector_store: BaseVectorStore):
    """æ¼”ç¤ºæ™ºèƒ½æ£€æµ‹åŠŸèƒ½"""
    detector = IntelligentBoundaryDetector(vector_store)
    
    # æµ‹è¯•å…³é”®è¯åˆ—è¡¨
    test_keywords = [
        "suv",                    # åˆ›ä¸šç­¾è¯ï¼ˆåº”è¯¥ç›¸å…³ï¼‰
        "express entry",          # å¿«é€Ÿé€šé“ï¼ˆåº”è¯¥ç›¸å…³ï¼‰
        "æ±½è½¦æ¨è",                # æ±½è½¦ï¼ˆåº”è¯¥ä¸ç›¸å…³ï¼‰
        "pnp",                    # çœæåï¼ˆåº”è¯¥ç›¸å…³ï¼‰
        "å¤©æ°”æ€ä¹ˆæ ·",              # å¤©æ°”ï¼ˆåº”è¯¥ä¸ç›¸å…³ï¼‰
        "é…å¶æ‹…ä¿",               # ç§»æ°‘é¡¹ç›®ï¼ˆåº”è¯¥ç›¸å…³ï¼‰
        "ä¹°æˆ¿æŠ•èµ„",               # æŠ•èµ„ï¼ˆå¯èƒ½ä¸ç›¸å…³ï¼‰
        "startup visa",           # åˆ›ä¸šç­¾è¯ï¼ˆåº”è¯¥ç›¸å…³ï¼‰
        "lmia",                   # åŠ³åŠ¨åŠ›å¸‚åœºå½±å“è¯„ä¼°ï¼ˆåº”è¯¥ç›¸å…³ï¼‰
        "çœ‹ç”µå½±"                  # å¨±ä¹ï¼ˆåº”è¯¥ä¸ç›¸å…³ï¼‰
    ]
    
    print("ğŸ§ª æ™ºèƒ½è¾¹ç•Œæ£€æµ‹æµ‹è¯•ç»“æœï¼š")
    print("=" * 80)
    
    results = test_multiple_keywords(detector, test_keywords)
    
    for result in results:
        status = "âœ… ç›¸å…³" if result["is_immigration_related"] else "âŒ ä¸ç›¸å…³"
        print(f"{status} | {result['keyword']:<15} | åˆ†æ•°: {result['similarity_score']:.3f} | {result['reason'][:50]}...")
    
    return results

if __name__ == "__main__":
    # å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œæ‰§è¡Œæ¼”ç¤º
    from src.infrastructure.vector_store.factory import VectorStoreFactory
    
    vector_store = VectorStoreFactory.get_vector_store()
    demo_intelligent_detection(vector_store) 