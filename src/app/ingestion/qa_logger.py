# src/app/ingestion/qa_logger.py
"""
æ¨¡å—åç§°ï¼šqa_logger.py

åŠŸèƒ½ï¼š
- å°†æ¯è½®é—®ç­”ç»“æ„åŒ–å­˜å‚¨ä¸ºçŸ¥è¯†ç‰‡æ®µï¼Œå¹¶å†™å…¥ Qdrant å‘é‡æ•°æ®åº“
- è®°å½•å¯¹è¯å†å²åˆ° CONVERSATION_COLLECTION
- è®°å½•æ ‡å‡†åŒ–æŸ¥è¯¢åˆ° CANONICAL_COLLECTION
- è‡ªåŠ¨è¿›è¡Œè¯­ä¹‰é—®æ³•è§„èŒƒåŒ–å’Œå…³é”®è¯æ‰“æ ‡ç­¾
"""
import uuid
import datetime
from typing import Optional
from src.infrastructure.vector_store.embedding_router import get_embedding
from src.infrastructure.vector_store.base import BaseVectorStore
from src.infrastructure.vector_store.qdrant import QdrantVectorStore
from src.app.agent.query_normalizer import transform_query_to_canonical_form
from src.app.ingestion.tagger import auto_tag
from src.infrastructure.llm.base import BaseLLM

def log_conversation(user_id: str, question: str, answer: str, vector_store: BaseVectorStore) -> None:
    """è®°å½•å¯¹è¯å†å²"""
    conversation_point = {
        "id": str(uuid.uuid4()),
        "vector": get_embedding(question + answer),
        "payload": {
            "user_id": user_id,
            "question": question,
            "answer": answer,
            "timestamp": datetime.datetime.utcnow().isoformat(),
        }
    }
    vector_store.upsert(
        collection_name=QdrantVectorStore.CONVERSATION_COLLECTION,
        points=[conversation_point]
    )
    print(f"âœ… å¯¹è¯å·²è®°å½•åˆ°å†å²")

def log_canonical_query(question: str, canonical_form: str, answer: str, vector_store: BaseVectorStore) -> None:
    """è®°å½•æ ‡å‡†åŒ–æŸ¥è¯¢"""
    canonical_point = {
        "id": str(uuid.uuid4()),
        "vector": get_embedding(canonical_form),
        "payload": {
            "original_question": question,
            "canonical_form": canonical_form,
            "answer": answer,
            "created_at": datetime.datetime.utcnow().isoformat(),
        }
    }
    vector_store.upsert(
        collection_name=QdrantVectorStore.CANONICAL_COLLECTION,
        points=[canonical_point]
    )
    print(f"âœ… æ ‡å‡†åŒ–æŸ¥è¯¢å·²è®°å½•")

def log_qa_to_knowledge_base(
    question: str, 
    answer: str, 
    vector_store: BaseVectorStore,
    llm: BaseLLM,
    user_id: Optional[str] = None, 
    domain: str = "canada_immigration"
) -> None:
    """
    å°†ç”¨æˆ·ä¸€è½®é—®ç­”è®°å½•åˆ°å¤šä¸ªé›†åˆä¸­ã€‚
    
    Args:
        question: ç”¨æˆ·åŸå§‹æé—®
        answer: ç”Ÿæˆçš„å›ç­”å†…å®¹
        vector_store: å‘é‡å­˜å‚¨å®¢æˆ·ç«¯
        llm: è¯­è¨€æ¨¡å‹å®¢æˆ·ç«¯
        user_id: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼‰
        domain: é¢†åŸŸæ ‡è®°
    """
    # 1. è®°å½•å¯¹è¯å†å²
    if user_id:
        log_conversation(user_id, question, answer, vector_store)
    
    # 2. ç”Ÿæˆå¹¶è®°å½•æ ‡å‡†åŒ–æŸ¥è¯¢
    canonical_form = transform_query_to_canonical_form(question, llm=llm, vector_store=vector_store)
    log_canonical_query(question, canonical_form, answer, vector_store)
    
    # 3. ç”Ÿæˆæ ‡ç­¾
    tags = auto_tag(canonical_form + "\n" + answer, domain=domain)
    
    print(f"ğŸ“¥ é—®ç­”å¤„ç†å®Œæˆï¼ˆæ ‡ç­¾ï¼š{tags}ï¼‰")
