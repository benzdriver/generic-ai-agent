# ğŸ¤– Intelligent Crawler Service

ä¸€ä¸ªå®Œå…¨è‡ªä¸»çš„AIé©±åŠ¨çˆ¬è™«ç³»ç»Ÿï¼Œä¸“ä¸ºæ„å»ºé«˜è´¨é‡çŸ¥è¯†åº“è®¾è®¡ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- **AIé©±åŠ¨çš„é¡µé¢ä»·å€¼è¯„ä¼°**: è‡ªåŠ¨åˆ¤æ–­é¡µé¢æ˜¯å¦å€¼å¾—çˆ¬å–
- **æ™ºèƒ½å†…å®¹æå–**: è¯†åˆ«å¹¶æå–è¡¨æ ¼ã€PDFã€åŠ¨æ€å†…å®¹
- **è‡ªåŠ¨è´¨é‡æ§åˆ¶**: å¤šå±‚éªŒè¯ç¡®ä¿æ•°æ®å‡†ç¡®æ€§
- **å¢é‡æ›´æ–°**: æ™ºèƒ½æ£€æµ‹å˜åŒ–ï¼Œåªæ›´æ–°å¿…è¦å†…å®¹
- **å‘é‡åŒ–å­˜å‚¨**: è‡ªåŠ¨è½¬æ¢ä¸ºå‘é‡å¹¶å­˜å‚¨åˆ°æ•°æ®åº“
- **å®Œå…¨è‡ªåŠ¨åŒ–**: æ— éœ€äººå·¥å¹²é¢„çš„ç«¯åˆ°ç«¯æµç¨‹

## ğŸš€ å¿«é€Ÿå¼€å§‹

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/yourorg/intelligent-crawler-service
cd intelligent-crawler-service

# 2. é…ç½®ç¯å¢ƒ
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œæ·»åŠ å¿…è¦çš„ API keys

# 3. å¯åŠ¨æœåŠ¡
docker-compose up -d

# 4. æµ‹è¯•API
curl http://localhost:8080/health
```

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€çˆ¬å–

```python
import requests

# åˆ›å»ºçˆ¬å–ä»»åŠ¡
response = requests.post('http://localhost:8080/api/v1/crawl', json={
    'urls': ['https://www.canada.ca/immigration'],
    'config': {
        'max_depth': 3,
        'ai_evaluation': True,
        'min_quality_score': 0.6
    }
})

job_id = response.json()['job_id']
```

### æœç´¢çŸ¥è¯†åº“

```python
# æœç´¢
results = requests.post('http://localhost:8080/api/v1/search', json={
    'query': 'Express Entry requirements',
    'collection': 'immigration_docs'
})
```

## ğŸ—ï¸ æ¶æ„

```
intelligent-crawler-service/
â”œâ”€â”€ api/                 # FastAPI åº”ç”¨
â”œâ”€â”€ crawler/            # æ™ºèƒ½çˆ¬è™«æ ¸å¿ƒ
â”œâ”€â”€ ai/                 # AIè¯„ä¼°å’Œåˆ†æ
â”œâ”€â”€ vectorizer/         # å‘é‡åŒ–æœåŠ¡
â”œâ”€â”€ updater/           # å¢é‡æ›´æ–°æœåŠ¡
â”œâ”€â”€ storage/           # å­˜å‚¨é€‚é…å™¨
â”œâ”€â”€ docker/            # Dockeré…ç½®
â””â”€â”€ tests/             # æµ‹è¯•å¥—ä»¶
```

## ğŸ“ License

MIT License