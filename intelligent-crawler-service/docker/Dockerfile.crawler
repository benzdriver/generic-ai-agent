# Crawler Worker Dockerfile
FROM python:3.11-slim

# Install system dependencies including Playwright dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    wget \
    gnupg \
    libglib2.0-0 \
    libnss3 \
    libnspr4 \
    libatk1.0-0 \
    libatk-bridge2.0-0 \
    libcups2 \
    libdrm2 \
    libdbus-1-3 \
    libxkbcommon0 \
    libatspi2.0-0 \
    libx11-6 \
    libxcomposite1 \
    libxdamage1 \
    libxext6 \
    libxfixes3 \
    libxrandr2 \
    libgbm1 \
    libxcb1 \
    libxss1 \
    libgtk-3-0 \
    libpango-1.0-0 \
    libcairo2 \
    libasound2 \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy requirements
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user
RUN useradd -m -u 1000 crawler && chown -R crawler:crawler /app

# Install Playwright browsers with dependencies as crawler user
USER crawler
RUN pip install --user playwright && \
    python -m playwright install chromium

# Create download directory
RUN mkdir -p /app/downloads

# Run the crawler worker
CMD ["celery", "-A", "crawler.tasks", "worker", "--loglevel=info", "--concurrency=4"]