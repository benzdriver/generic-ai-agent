#!/usr/bin/env python3
# tests/test_all_collections.py

"""
æµ‹è¯•æ‰€æœ‰Qdranté›†åˆï¼šéªŒè¯æ‰€æœ‰é›†åˆæ˜¯å¦å¯ä»¥æ­£å¸¸æ·»åŠ å‘é‡å’Œæœç´¢
"""

import sys
import os
from pathlib import Path
import unittest
import numpy as np
import uuid
import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from qdrant_client import QdrantClient
from qdrant_client.http import models
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
env_path = Path(__file__).parent.parent / '.env'
if env_path.exists():
    load_dotenv(env_path)

# ç›´æ¥å¯¼å…¥é›†åˆåç§°å¸¸é‡ï¼Œé¿å…åˆå§‹åŒ–æ•´ä¸ªé…ç½®
CANONICAL_COLLECTION = "canonical_queries"
CONVERSATION_COLLECTION = "conversations"
DOCUMENT_COLLECTION = "documents"
MERGED_COLLECTION = "merged_knowledge"

class TestAllCollections(unittest.TestCase):
    """æµ‹è¯•æ‰€æœ‰Qdranté›†åˆçš„åŠŸèƒ½"""
    
    @classmethod
    def setUpClass(cls):
        """æµ‹è¯•ç±»åˆå§‹åŒ–"""
        print("\nå‡†å¤‡Qdranté›†åˆæµ‹è¯•ç¯å¢ƒ...")
        
        # ä»ç¯å¢ƒå˜é‡è·å–URLå’ŒAPIå¯†é’¥
        cls.url = os.environ.get('QDRANT_URL')
        cls.api_key = os.environ.get('QDRANT_API_KEY')
        
        if not cls.url or not cls.api_key:
            print("âš ï¸ æœªè®¾ç½®QDRANT_URLæˆ–QDRANT_API_KEYç¯å¢ƒå˜é‡ï¼Œè¯·ç¡®ä¿å·²è®¾ç½®æ­£ç¡®çš„APIå¯†é’¥")
            cls.client = None
            return
        
        try:
            # åˆ›å»ºå®¢æˆ·ç«¯
            cls.client = QdrantClient(url=cls.url, api_key=cls.api_key)
            print(f"âœ… æˆåŠŸè¿æ¥åˆ°Qdrant: {cls.url}")
            
            # å‡†å¤‡æµ‹è¯•æ•°æ®
            cls.now = datetime.datetime.utcnow().isoformat()
            
            # æ–‡æ¡£é›†åˆæµ‹è¯•æ•°æ®
            cls.document_test_data = [
                (np.random.rand(1536).tolist(), {
                    "text": "åŠ æ‹¿å¤§ç§»æ°‘æ”¿ç­–æ¦‚è¿°",
                    "source": "IRCCå®˜æ–¹æ–‡æ¡£",
                    "category": "æ”¿ç­–",
                    "test_id": "doc_test_1"
                }),
                (np.random.rand(1536).tolist(), {
                    "text": "åŠ æ‹¿å¤§æŠ€æœ¯ç§»æ°‘ç”³è¯·æµç¨‹",
                    "source": "IRCCå®˜æ–¹æ–‡æ¡£",
                    "category": "æµç¨‹",
                    "test_id": "doc_test_2"
                })
            ]
            
            # è§„èŒƒåŒ–æŸ¥è¯¢é›†åˆæµ‹è¯•æ•°æ®
            cls.canonical_test_data = [
                (np.random.rand(1536).tolist(), {
                    "raw": "æ€ä¹ˆç”³è¯·åŠ æ‹¿å¤§ç§»æ°‘?",
                    "canonical": "åŠ æ‹¿å¤§ç§»æ°‘ç”³è¯·æµç¨‹",
                    "created_at": cls.now,
                    "test_id": "canonical_test_1"
                }),
                (np.random.rand(1536).tolist(), {
                    "raw": "å­¦ç”Ÿç­¾è¯éœ€è¦ä»€ä¹ˆææ–™?",
                    "canonical": "åŠ æ‹¿å¤§å­¦ç”Ÿç­¾è¯ç”³è¯·ææ–™æ¸…å•",
                    "created_at": cls.now,
                    "test_id": "canonical_test_2"
                })
            ]
            
            # å¯¹è¯å†å²é›†åˆæµ‹è¯•æ•°æ®
            cls.conversation_test_data = [
                (np.random.rand(1536).tolist(), {
                    "user_id": "test_user_1",
                    "question": "åŠ æ‹¿å¤§æŠ€æœ¯ç§»æ°‘éœ€è¦ä»€ä¹ˆæ¡ä»¶?",
                    "answer": "åŠ æ‹¿å¤§æŠ€æœ¯ç§»æ°‘ä¸»è¦é€šè¿‡Express Entryç³»ç»Ÿ...",
                    "timestamp": cls.now,
                    "test_id": "conv_test_1"
                }),
                (np.random.rand(1536).tolist(), {
                    "user_id": "test_user_2",
                    "question": "æˆ‘éœ€è¦å¤šå°‘åˆ†æ‰èƒ½ç”³è¯·EE?",
                    "answer": "Express Entryè¯„åˆ†ç³»ç»ŸåŸºäºå¤šä¸ªå› ç´ ...",
                    "timestamp": cls.now,
                    "test_id": "conv_test_2"
                })
            ]
            
            # åˆå¹¶çŸ¥è¯†ç‚¹é›†åˆæµ‹è¯•æ•°æ®
            cls.merged_test_data = [
                (np.random.rand(1536).tolist(), {
                    "text": "åŠ æ‹¿å¤§æŠ€æœ¯ç§»æ°‘ç»¼åˆæŒ‡å—",
                    "merged_from": ["id1", "id2", "id3"],
                    "created_at": cls.now,
                    "type": "merged_cluster",
                    "test_id": "merged_test_1"
                }),
                (np.random.rand(1536).tolist(), {
                    "text": "åŠ æ‹¿å¤§å­¦ç”Ÿç­¾è¯ç”³è¯·å…¨æµç¨‹",
                    "merged_from": ["id4", "id5"],
                    "created_at": cls.now,
                    "type": "merged_cluster",
                    "test_id": "merged_test_2"
                })
            ]
            
        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥: {str(e)}")
            cls.client = None
    
    def _test_collection(self, collection_name, test_data):
        """æµ‹è¯•ç‰¹å®šé›†åˆçš„è¯»å†™åŠŸèƒ½"""
        if not self.client:
            self.skipTest("Qdrantå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        
        print(f"\n{'='*30}")
        print(f"ğŸ” æµ‹è¯•é›†åˆ: {collection_name}")
        print(f"{'='*30}")
        
        # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
        self.assertTrue(self.client.collection_exists(collection_name), 
                       f"é›†åˆ {collection_name} ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ initialize_collections.py")
        
        # æ·»åŠ æµ‹è¯•å‘é‡
        print("\næ·»åŠ æµ‹è¯•å‘é‡...")
        points = []
        ids = []  # ä¿å­˜IDä»¥ä¾¿åç»­ä½¿ç”¨
        
        for i, (vector, payload) in enumerate(test_data):
            # ä½¿ç”¨UUIDä½œä¸ºç‚¹ID
            point_id = str(uuid.uuid4())
            ids.append(point_id)
            
            points.append(models.PointStruct(
                id=point_id,
                vector=vector,
                payload=payload
            ))
        
        self.client.upsert(
            collection_name=collection_name,
            points=points
        )
        print(f"âœ… æˆåŠŸæ·»åŠ  {len(points)} ä¸ªæµ‹è¯•å‘é‡")
        
        # æµ‹è¯•æœç´¢
        print("\næµ‹è¯•å‘é‡æœç´¢...")
        search_vector = np.random.rand(1536).tolist()  # éšæœºæœç´¢å‘é‡
        results = self.client.search(
            collection_name=collection_name,
            query_vector=search_vector,
            limit=2
        )
        
        self.assertTrue(len(results) > 0, "æœç´¢åº”è¿”å›ç»“æœ")
        print(f"âœ… æœç´¢æˆåŠŸï¼Œæ‰¾åˆ° {len(results)} ä¸ªç»“æœ:")
        for i, result in enumerate(results):
            print(f"  {i+1}. ID: {result.id}")
            print(f"     ç›¸ä¼¼åº¦: {result.score:.4f}")
            print(f"     Payload: {result.payload}")
        
        return True
    
    def test_document_collection(self):
        """æµ‹è¯•æ–‡æ¡£é›†åˆ"""
        self._test_collection(DOCUMENT_COLLECTION, self.document_test_data)
    
    def test_canonical_collection(self):
        """æµ‹è¯•è§„èŒƒåŒ–æŸ¥è¯¢é›†åˆ"""
        self._test_collection(CANONICAL_COLLECTION, self.canonical_test_data)
    
    def test_conversation_collection(self):
        """æµ‹è¯•å¯¹è¯å†å²é›†åˆ"""
        self._test_collection(CONVERSATION_COLLECTION, self.conversation_test_data)
    
    def test_merged_collection(self):
        """æµ‹è¯•åˆå¹¶çŸ¥è¯†ç‚¹é›†åˆ"""
        self._test_collection(MERGED_COLLECTION, self.merged_test_data)

if __name__ == "__main__":
    print("=" * 70)
    print("ğŸ” æµ‹è¯•æ‰€æœ‰Qdranté›†åˆ")
    print("=" * 70)
    unittest.main() 